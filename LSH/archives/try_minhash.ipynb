{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from PIL import Image\n",
    "import imagehash\n",
    "import argparse\n",
    "import shelve\n",
    "import glob\n",
    "import os\n",
    "import re\n",
    "import random\n",
    "import time\n",
    "import binascii\n",
    "import hashlib\n",
    "from bisect import bisect_right\n",
    "from heapq import heappop, heappush\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generating random hash functions...\n"
     ]
    }
   ],
   "source": [
    "# Time this step.\n",
    "# print ('\\nGenerating random hash functions...')\n",
    "# Record the maximum shingle ID that we assigned.\n",
    "maxShingleID = 2**32-1\n",
    "\n",
    "# We need the next largest prime number above 'maxShingleID'.\n",
    "# I looked this value up here: \n",
    "# http://compoasso.free.fr/primelistweb/page/prime/liste_online_en.php\n",
    "nextPrime = 4294967311"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickRandomCoeffs(k):\n",
    "    # Create a list of 'k' random values.\n",
    "    randList = []\n",
    "\n",
    "    while k > 0:\n",
    "    # Get a random shingle ID.\n",
    "        randIndex = random.randint(0, maxShingleID) \n",
    "\n",
    "        # Ensure that each random number is unique.\n",
    "        while randIndex in randList:\n",
    "            randIndex = random.randint(0, maxShingleID) \n",
    "\n",
    "        # Add the random number to the list.\n",
    "        randList.append(randIndex)\n",
    "        k = k - 1\n",
    "    return randList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3057765316, 1989347376, 621872310, 2866481810, 2098430060]\n"
     ]
    }
   ],
   "source": [
    "print(pickRandomCoeffs(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64c6cee6331382c1\n",
      "==================\n",
      "64c28f0723339ecd\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "coeffA = pickRandomCoeffs(10)\n",
    "coeffB = pickRandomCoeffs(10)\n",
    "\n",
    "# List of documents represented as signature vectors\n",
    "signatures = []\n",
    "\n",
    "# Rather than generating a random permutation of all possible shingles, \n",
    "# we'll just hash the IDs of the shingles that are *actually in the document*,\n",
    "# then take the lowest resulting hash code value. This corresponds to the index \n",
    "# of the first shingle that you would have encountered in the random order.\n",
    "\n",
    "# For each document...\n",
    "image_hashset = []\n",
    "# for imagePath in glob.glob(\"dataset1\" + \"/*.jpg\"):\n",
    "for imagePath in glob.glob(\"101_ObjectCategories/accordion\" + \"/*.jpg\"):\n",
    "    \n",
    "    # Get the hashfunction for the image\n",
    "    image = Image.open(imagePath)\n",
    "    h = str(imagehash.dhash(image))\n",
    "    image_hashset.append(h)\n",
    "  \n",
    "\n",
    "image_hashset2 = []\n",
    "# for imagePath in glob.glob(\"dataset2\" + \"/*.jpg\"):\n",
    "for imagePath in glob.glob(\"101_ObjectCategories/accordion2\" + \"/*.jpg\"):\n",
    "\n",
    "    # Get the hashfunction for the image\n",
    "    image = Image.open(imagePath)\n",
    "    h = str(imagehash.dhash(image))\n",
    "    image_hashset2.append(h)\n",
    "\n",
    "\n",
    "# image_hashset_test = []\n",
    "# image_test = Image.open(\"image_0020.jpg\")\n",
    "# h_test = str(imagehash.dhash(image_test))\n",
    "# image_hashset_test.append(h_test)\n",
    "print(image_hashset[0])\n",
    "print('==================')\n",
    "print(image_hashset[5])\n",
    "print(len(image_hashset[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4375"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar(image_hashset[0],image_hashset[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95041122, 77781479, 61800884, 34315693, 132215246, 5540555, 17261061, 46891330, 96953454, 7747837]\n",
      "[77960296, 77781479, 61800884, 34315693, 132215246, 5540555, 17261061, 46891330, 96953454, 7747837]\n"
     ]
    }
   ],
   "source": [
    "signature1 = []\n",
    "signature2 = []\n",
    "hh = []\n",
    "\n",
    "# For each of the random hash functions...\n",
    "for i in range(0, 10):\n",
    "    # For each of the shingles actually in the document, calculate its hash code\n",
    "    # using hash function 'i'. \n",
    "\n",
    "    # Track the lowest hash ID seen. Initialize 'minHashCode' to be greater than\n",
    "    # the maximum possible value output by the hash.\n",
    "    minHashCode1 = nextPrime + 1\n",
    "    minHashCode2 = nextPrime + 1\n",
    "\n",
    "    # For each shingle in the document...\n",
    "    for image_hash in image_hashset:\n",
    "        # Evaluate the hash function.\n",
    "        image_ID = abs(hash(image_hash)) % (10 ** 8)\n",
    "        hashCode = (coeffA[i] * image_ID + coeffB[i]) % nextPrime \n",
    "        hh.append(hashCode)\n",
    "        # Track the lowest hash code seen.\n",
    "        if hashCode < minHashCode1:\n",
    "            minHashCode1 = hashCode\n",
    "\n",
    "    # Add the smallest hash code value as component number 'i' of the signature.\n",
    "    signature1.append(minHashCode1)\n",
    "    \n",
    "#     image_ID_test = abs(hash(h_test)) % (10 ** 8)\n",
    "#     hashCode_test = (coeffA[i] * image_ID + coeffB[i]) % nextPrime \n",
    "\n",
    "#     # Track the lowest hash code seen.\n",
    "#     if hashCode_test < minHashCode2:\n",
    "#         minHashCode2 = hashCode_test\n",
    "#     print(minHashCode2)\n",
    "    \n",
    "    for image_hash in image_hashset2:\n",
    "        # Evaluate the hash function.\n",
    "        image_ID = abs(hash(image_hash)) % (10 ** 8)\n",
    "        hashCode = (coeffA[i] * image_ID + coeffB[i]) % nextPrime \n",
    "\n",
    "        # Track the lowest hash code seen.\n",
    "        if hashCode < minHashCode2:\n",
    "            minHashCode2 = hashCode\n",
    "\n",
    "    # Add the smallest hash code value as component number 'i' of the signature.\n",
    "    signature2.append(minHashCode2)\n",
    "\n",
    "print(signature1)\n",
    "print(signature2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Estimated Jaccard Similarity = 0.9\n"
     ]
    }
   ],
   "source": [
    "same_items = 0\n",
    "for i in range(0, 10):\n",
    "    if (signature1[i]==signature2[i]):\n",
    "        same_items += 1\n",
    "print (\"\\nEstimated Jaccard Similarity = \" + str(same_items/10))\n",
    "# same = 0\n",
    "# for i in range(len(hh)):\n",
    "#     for j in range(len(signature2)):\n",
    "#         if (hh[i] == signature2[j] ):\n",
    "#             same += 1\n",
    "# print(same)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of common images: 45\n",
      "Number of total images: 65\n",
      "\n",
      "Exact Jaccard Similarity = 0.6923076923076923\n"
     ]
    }
   ],
   "source": [
    "exact_num = len(set(image_hashset).intersection(image_hashset2))\n",
    "exact_total = len(set(image_hashset).union(image_hashset2))\n",
    "\n",
    "print(\"\\nNumber of common images: \"+ str(exact_num))\n",
    "print(\"Number of total images: \" + str(exact_total))\n",
    "J = exact_num/exact_total\n",
    "print(\"\\nExact Jaccard Similarity = \" + str(J))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate neighbours with Jaccard similarity > 0.5 ['m3', 'm2']\n"
     ]
    }
   ],
   "source": [
    "from datasketch import MinHash, MinHashLSH\n",
    "\n",
    "set1 = set(['minhash', 'is', 'a', 'probabilistic', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'datasets'])\n",
    "set2 = set(['minhash', 'is', 'a', 'probability', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'documents'])\n",
    "set3 = set(['minhash', 'is', 'probability', 'data', 'structure', 'for',\n",
    "            'estimating', 'the', 'similarity', 'between', 'documents'])\n",
    "\n",
    "m1 = MinHash(num_perm=128)\n",
    "m2 = MinHash(num_perm=128)\n",
    "m3 = MinHash(num_perm=128)\n",
    "for d in set1:\n",
    "    m1.update(d.encode('utf8'))\n",
    "for d in set2:\n",
    "    m2.update(d.encode('utf8'))\n",
    "for d in set3:\n",
    "    m3.update(d.encode('utf8'))\n",
    "\n",
    "# Create LSH index\n",
    "lsh = MinHashLSH(threshold=0.5, num_perm=128)\n",
    "lsh.insert(\"m2\", m2)\n",
    "lsh.insert(\"m3\", m3)\n",
    "result = lsh.query(m1)\n",
    "print(\"Approximate neighbours with Jaccard similarity > 0.5\", result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
